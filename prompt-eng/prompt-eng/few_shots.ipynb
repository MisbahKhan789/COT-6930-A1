{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shots Prompting\n",
    "\n",
    "Few-shot prompting can be used as a technique to enable in-context learning where we provide demonstrations in the prompt to steer the model to better performance. The demonstrations serve as conditioning for subsequent examples where we would like the model to generate a response.\n",
    "\n",
    "## References:\n",
    "* [Touvron et al. 2023](https://arxiv.org/pdf/2302.13971.pdf): present few shot properties  when models were scaled to a sufficient size\n",
    "* [Kaplan et al., 2020](https://arxiv.org/abs/2001.08361)\n",
    "* [Brown et al. 2020](https://arxiv.org/abs/2005.14165)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Ffew_shots.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To automate the requirement analysis process for the Study Companion Bot, I would follow a similar approach as in Example 3: An educational AI assistant. Here's a step-by-step guide on how to do it:\n",
      "\n",
      "1. **Data Collection**:\n",
      "\t* Gather historical chat logs from the Discord server.\n",
      "\t* Collect past queries and Q&A sessions with students.\n",
      "\t* Integrate external resources, such as textbooks, online courses, and study materials.\n",
      "2. **Text Preprocessing**:\n",
      "\t* Clean and preprocess the collected data by removing noise, punctuation, and special characters.\n",
      "\t* Tokenize text into individual words or phrases (e.g., using NLTK or spaCy).\n",
      "3. **Topic Modeling**:\n",
      "\t* Apply topic modeling techniques (e.g., Latent Dirichlet Allocation (LDA)) to identify underlying topics in the collected data.\n",
      "\t* This will help identify common themes, concepts, and areas of difficulty for students.\n",
      "4. **Sentiment Analysis**:\n",
      "\t* Perform sentiment analysis on the collected data to gauge student emotions and concerns.\n",
      "\t* This can help identify areas where students need extra support or encouragement.\n",
      "5. **Knowledge Graph Construction**:\n",
      "\t* Create a knowledge graph by integrating the preprocessed data, topic models, and sentiment analysis results.\n",
      "\t* The knowledge graph will represent relationships between concepts, topics, and student needs.\n",
      "6. **Gap Identification**:\n",
      "\t* Analyze the knowledge graph to identify gaps in existing learning resources.\n",
      "\t* Use techniques like clustering or network analysis to visualize relationships between concepts and identify areas where students are struggling.\n",
      "7. **Tutoring Scope Refining**:\n",
      "\t* Based on the gap identification results, refine the tutoring scope of the Study Companion Bot.\n",
      "\t* Update the bot's knowledge base with new topics, resources, and strategies to address identified gaps.\n",
      "\n",
      "To implement this approach, I would use a combination of natural language processing (NLP) libraries like NLTK, spaCy, and scikit-learn for machine learning tasks. For topic modeling, I would utilize libraries like Gensim or PyLDA. Sentiment analysis can be performed using libraries like TextBlob or VaderSentiment.\n",
      "\n",
      "Here's some sample Python code to get you started:\n",
      "```python\n",
      "import nltk\n",
      "from nltk.tokenize import word_tokenize\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from gensim import corpora, models\n",
      "\n",
      "# Load historical chat logs and past queries\n",
      "chat_logs = pd.read_csv('chat_logs.csv')\n",
      "queries = pd.read_csv('queries.csv')\n",
      "\n",
      "# Preprocess text data\n",
      "nltk.download('punkt')\n",
      "tokenized_data = [word_tokenize(text) for text in chat_logs['text'] + queries['query']]\n",
      "\n",
      "# Create TF-IDF vectorizer\n",
      "vectorizer = TfidfVectorizer()\n",
      "tfidf_matrix = vectorizer.fit_transform(tokenized_data)\n",
      "\n",
      "# Apply topic modeling using LDA\n",
      "lda_model = LatentDirichletAllocation(n_topics=10)\n",
      "topic_distributions = lda_model.fit_transform(tfidf_matrix)\n",
      "\n",
      "# Perform sentiment analysis using TextBlob\n",
      "from textblob import TextBlob\n",
      "sentiment_analyzer = TextBlob()\n",
      "sentiment_results = [sentiment_analyzer.sentiment(text) for text in chat_logs['text'] + queries['query']]\n",
      "\n",
      "# Construct knowledge graph\n",
      "knowledge_graph = {}\n",
      "for topic, distribution in zip(lda_model.components_, topic_distributions):\n",
      "    knowledge_graph[topic] = {\n",
      "        'concepts': [f'concept_{i}' for i in range(distribution.shape[0])],\n",
      "        'sentiment': sentiment_results[topic]\n",
      "    }\n",
      "\n",
      "# Identify gaps in existing learning resources\n",
      "gaps = []\n",
      "for concept, info in knowledge_graph.items():\n",
      "    if len(info['concepts']) < 5:  # arbitrary threshold\n",
      "        gaps.append(concept)\n",
      "\n",
      "# Refine tutoring scope based on gap identification\n",
      "tutoring_scope = [concept for concept in knowledge_graph.keys() if concept not in gaps]\n",
      "```\n",
      "This code snippet demonstrates the initial steps of automating requirement analysis for the Study Companion Bot. The actual implementation would require more extensive processing and refinement, but this should give you a starting point to work from.\n",
      "Time taken: 45.924s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## FEW SHOTS PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "#MESSAGE = \"Calculate 984 * log(2)\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "#FEW_SHOT = \"You are a math teacher. If student asked 1 + 1 you answer 2. If student ask 987 * 2 you answer only 1974. Student asked; provide the result only: \"\n",
    "#PROMPT = FEW_SHOT + '\\n' + MESSAGE \n",
    "PROMPT = \"\"\"Consider yourself an automation expert in software development. You are tasked with developing a Study Companion Bot for a Discord-based chatbot. The chatbot should provide personalized tutoring, assist students with Q&A, and dynamically update its knowledge based on available resources.\n",
    "\n",
    "Here are some examples of automated requirement analysis approaches for similar applications:\n",
    "Example 1: A customer service chatbot extracts user pain points from historical chat logs and clusters common issues using NLP techniques.\n",
    "Example 2: A legal AI assistant uses structured templates to auto-generate requirements based on frequently asked legal questions and precedent cases.\n",
    "Example 3: An educational AI assistant processes forum discussions and past queries to identify gaps in existing learning resources, refining its tutoring scope dynamically.*\n",
    "\n",
    "Given these examples, how would you automate the requirement analysis process for the Study Companion Bot?\"\"\"\n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0, \n",
    "                         num_ctx=8192, \n",
    "                         num_predict=8192)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to improve it?\n",
    "\n",
    "Following the findings from [Min et al. (2022)](https://arxiv.org/abs/2202.12837), here are a few more tips about demonstrations/exemplars when doing few-shot:\n",
    "\n",
    "* \"the label space and the distribution of the input text specified by the demonstrations are both important (regardless of whether the labels are correct for individual inputs)\"\n",
    "* the format you use also plays a key role in performance, even if you just use random labels, this is much better than no labels at all.\n",
    "* additional results show that selecting random labels from a true distribution of labels (instead of a uniform distribution) also helps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
