{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Consistency Prompting\n",
    "\n",
    "One of the more advanced techniques in prompt engineering is self-consistency, introduced by `Wang et al. (2022)`. \n",
    "\n",
    "This method seeks to improve upon the traditional greedy decoding typically used in chain-of-thought (CoT) prompting. \n",
    "\n",
    "The core concept involves sampling multiple diverse reasoning paths through few-shot CoT and leveraging these variations to determine the most consistent answer. The technique  enhances the effectiveness of CoT prompting, particularly for tasks requiring arithmetic and commonsense reasoning.\n",
    "\n",
    "## References:\n",
    "* [Wang et al. (2022)](https://arxiv.org/abs/2203.11171)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fself_consistency.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an automation expert, I'll outline multiple possible approaches to solving the problem of automating requirement analysis for the Study Companion Bot.\n",
      "\n",
      "**Approaches:**\n",
      "\n",
      "1. **Data-Driven Approach**: This approach involves automatically collecting and analyzing student questions to identify recurring topics and gaps in knowledge. The chatbot can use natural language processing (NLP) techniques to extract key concepts, entities, and relationships from student queries.\n",
      "2. **Rule-Based Approach**: This approach relies on predefined templates and structured forms to capture essential chatbot capabilities. The study companion bot can be designed with a set of pre-defined rules and templates that outline the expected interactions between students and the chatbot.\n",
      "3. **Machine Learning Approach**: This approach involves implementing NLP models that extract key requirement patterns from educational materials and chat logs. Machine learning algorithms can be trained on large datasets to identify patterns and relationships in student questions, allowing the chatbot to learn and improve over time.\n",
      "4. **Hybrid Approach**: This approach combines rule-based and data-driven methods to ensure adaptability while maintaining structured requirement gathering. The hybrid approach would involve using predefined templates and rules as a foundation, with additional data-driven analysis to refine and update the requirements.\n",
      "\n",
      "**Evaluation of Approaches:**\n",
      "\n",
      "After evaluating each approach, I recommend the **Hybrid Approach** as the most consistent, scalable, and effective solution for automating requirement analysis in the Study Companion Bot. Here's why:\n",
      "\n",
      "*   **Consistency**: The hybrid approach ensures consistency by combining structured rules with data-driven analysis. This allows for a balanced approach that maintains adaptability while ensuring that requirements are well-defined.\n",
      "*   **Scalability**: The hybrid approach is more scalable than the other approaches because it can handle large datasets and continuously update requirements based on student interactions.\n",
      "*   **Effectiveness**: By combining rule-based and data-driven methods, the hybrid approach ensures that the chatbot captures essential capabilities while also learning from student interactions. This allows for continuous improvement and refinement of the chatbot's responses.\n",
      "\n",
      "**Implementation Plan:**\n",
      "\n",
      "To implement the hybrid approach, I recommend the following steps:\n",
      "\n",
      "1.  **Define Predefined Templates and Rules**: Develop a set of predefined templates and rules that outline the expected interactions between students and the chatbot.\n",
      "2.  **Collect and Analyze Student Questions**: Collect student questions and analyze them using NLP techniques to extract key concepts, entities, and relationships.\n",
      "3.  **Train Machine Learning Models**: Train machine learning models on large datasets to identify patterns and relationships in student questions.\n",
      "4.  **Refine and Update Requirements**: Continuously refine and update the requirements based on student interactions and chat logs.\n",
      "\n",
      "By following this implementation plan, you can create a Study Companion Bot that is consistent, scalable, and effective in providing personalized tutoring and support to students.\n",
      "Time taken: 31.584s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## ZERO SHOT PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "#MESSAGE = \"What is 984 * log(2)\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "\n",
    "## @TODO \n",
    "#PROMPT = MESSAGE \n",
    "PROMPT = \"\"\"Consider yourself an automation expert in software development. You are building a Study Companion Bot for a Discord-based chatbot that offers personalized tutoring on a specific subject. The chatbot must provide accurate explanations, Q&A assistance, and study tips while dynamically improving its responses based on student interactions.\n",
    "\n",
    "To automate requirement analysis, generate multiple possible approaches to solving this problem. For example:\n",
    "Data-Driven Approach: Automatically collect and analyze student questions to identify recurring topics and gaps in knowledge.\n",
    "Rule-Based Approach: Use predefined templates and structured forms to capture essential chatbot capabilities.\n",
    "Machine Learning Approach: Implement NLP models that extract key requirement patterns from educational materials and chat logs.\n",
    "Hybrid Approach: Combine rule-based and data-driven methods to ensure adaptability while maintaining structured requirement gathering.\n",
    "\n",
    "After outlining these approaches, determine which combination would be the most consistent, scalable, and effective for automating requirement analysis in the Study Companion Bot.\"\"\"\n",
    "\n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0, \n",
    "                         num_ctx=8192, \n",
    "                         num_predict=8192)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
