{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain-of-Thought Prompting\n",
    "\n",
    "Chain-of-Thought (CoT) prompting enhances complex reasoning by encouraging the model to break down problems into intermediate reasoning steps. When combined with few-shot prompting, it can significantly improve performance on tasks that require multi-step reasoning before arriving at a response.\n",
    "\n",
    "## Automatic Chain-of-Thought (Auto-CoT)\n",
    "\n",
    "Traditionally, using CoT prompting with demonstrations involves manually crafting diverse and effective examples. This manual effort is time-consuming and can lead to less-than-optimal results. To address this, Zhang et al. (2022) introduced Auto-CoT, an automated approach that minimizes manual involvement. Their method uses the prompt “Let’s think step by step” to generate reasoning chains automatically for demonstrations. However, this automatic process is not immune to errors. To reduce the impact of such mistakes, the approach emphasizes the importance of diverse demonstrations.\n",
    "\n",
    "Auto-CoT operates in two main stages:\n",
    "\n",
    "1. **Question Clustering:** Questions from the dataset are grouped into clusters based on similarity or relevance.\n",
    "2. **Demonstration Sampling:** A representative question from each cluster is selected, and its reasoning chain is generated using Zero-Shot-CoT guided by simple heuristics.\n",
    "\n",
    "\n",
    "## References:\n",
    "\n",
    "* (Wei et al. (2022),)[https://arxiv.org/abs/2201.11903]\n",
    "* (OpenAI Documentation for Prompt Engineering)[https://platform.openai.com/docs/guides/prompt-engineering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fchain_of_thought.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To automate requirement analysis for the Study Companion Bot while ensuring adaptability and continuous improvement, I'll outline a step-by-step approach:\n",
      "\n",
      "**Step 1: Identify Key Stakeholders and Their Expectations**\n",
      "\n",
      "* Conduct stakeholder interviews to understand their needs, pain points, and goals.\n",
      "* Create a stakeholder matrix to categorize participants based on their level of influence and interest in the chatbot's development.\n",
      "* Document key expectations, such as:\n",
      "\t+ Quality of responses\n",
      "\t+ Response time\n",
      "\t+ User engagement metrics (e.g., conversation length, topic coverage)\n",
      "\t+ Integration with existing learning management systems or platforms\n",
      "\n",
      "**Step 2: Define Types of Interactions Students Will Have with the Bot**\n",
      "\n",
      "* Conduct user research to understand common pain points and interests among students.\n",
      "* Create a user persona to represent the target audience, including demographics, goals, and behaviors.\n",
      "* Develop a conversation flowchart to illustrate possible interactions between users and the chatbot.\n",
      "\n",
      "**Step 3: Collect and Preprocess Domain-Specific Knowledge**\n",
      "\n",
      "* Gather domain-specific knowledge from various sources, such as:\n",
      "\t+ Expert interviews\n",
      "\t+ Academic papers\n",
      "\t+ Online resources (e.g., textbooks, educational websites)\n",
      "\t+ Existing chatbot data\n",
      "* Preprocess knowledge by:\n",
      "\t+ Normalizing and standardizing terminology\n",
      "\t+ Extracting key concepts and entities\n",
      "\t+ Creating a knowledge graph to represent relationships between concepts\n",
      "\n",
      "**Step 4: Design Method for Extracting and Analyzing User Queries**\n",
      "\n",
      "* Develop a natural language processing (NLP) pipeline to analyze user queries, including:\n",
      "\t+ Tokenization and part-of-speech tagging\n",
      "\t+ Named entity recognition\n",
      "\t+ Dependency parsing\n",
      "\t+ Sentiment analysis\n",
      "* Create a query classification system to categorize user queries into topics or domains.\n",
      "* Implement a machine learning model to predict the most relevant responses based on user queries.\n",
      "\n",
      "**Step 5: Develop Automation Pipeline for Dynamic Updates**\n",
      "\n",
      "* Design a data pipeline to collect and preprocess new knowledge, including:\n",
      "\t+ Web scraping for online resources\n",
      "\t+ API integrations with external sources (e.g., educational databases)\n",
      "\t+ User feedback mechanisms (e.g., surveys, ratings)\n",
      "* Implement a continuous integration/continuous deployment (CI/CD) pipeline to automate updates to the chatbot's knowledge base.\n",
      "* Use version control systems (e.g., Git) to track changes and ensure reproducibility.\n",
      "\n",
      "**Adaptability and Continuous Improvement**\n",
      "\n",
      "To ensure adaptability and continuous improvement:\n",
      "\n",
      "1. **Monitor user feedback**: Collect and analyze user feedback through surveys, ratings, or other mechanisms to identify areas for improvement.\n",
      "2. **Update knowledge graph regularly**: Regularly update the knowledge graph with new information to reflect changes in the domain or user needs.\n",
      "3. **Refine NLP pipeline**: Continuously refine the NLP pipeline by incorporating new techniques, such as transfer learning or multi-task learning.\n",
      "4. **Integrate with emerging technologies**: Explore integration with emerging technologies, such as conversational AI or cognitive architectures, to enhance the chatbot's capabilities.\n",
      "\n",
      "By following this structured approach and incorporating adaptability and continuous improvement mechanisms, you can automate requirement analysis for the Study Companion Bot while ensuring its effectiveness and relevance over time.\n",
      "Time taken: 59.986s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## CHAIN-OF-THOUGHT  PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "#MESSAGE = \"200\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "CHAIN_OF_THOUGHT = f\"\"\"\n",
    "Consider yourself an automation expert in software development. You are developing a Study Companion Bot for a Discord-based chatbot that provides personalized tutoring assistance on a specific subject. The chatbot should be engaging, entertaining, and useful for students, leveraging natural language understanding and domain-specific knowledge for Q&A, explanations, and study tips. Additionally, it should be able to look for more information when needed.\n",
    "\n",
    "To automate the process of requirement analysis for this chatbot, follow a structured approach:\n",
    "- Identify key stakeholders and their expectations from the chatbot.\n",
    "- Define the types of interactions students will have with the bot.\n",
    "- Collect and preprocess domain-specific knowledge for the chatbot.\n",
    "- Design a method to extract and analyze user queries to refine requirements iteratively.\n",
    "- Develop an automation pipeline that dynamically updates the bot's knowledge base.\n",
    "\n",
    "Given this structured approach, how would you automate requirement analysis while ensuring adaptability and continuous improvement?\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = CHAIN_OF_THOUGHT \n",
    "\n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0, \n",
    "                         num_ctx=8192, \n",
    "                         num_predict=8192)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
